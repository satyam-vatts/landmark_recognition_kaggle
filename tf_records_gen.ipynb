{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "from tqdm import tqdm\n",
    "# %pip install -q efficientnet\n",
    "# %pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating TF Records: To save memory consumption."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Feature Conversion Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "def serialize_example(feature0, feature1, feature2):\n",
    "    feature = {\n",
    "        'id': _bytes_feature(feature0),\n",
    "        'image': _bytes_feature(feature1),\n",
    "        'target': _int64_feature(feature2)\n",
    "    }\n",
    "    example_proto = tf.train.Example(features = tf.train.Features(feature = feature))\n",
    "    return example_proto.SerializeToString()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing Images as TF records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TRAIN_IMAGE_DIR = 'landmark-recognition-2020/train'\n",
    "TRAIN = 'landmark-recognition-2020/train_encoded.csv'\n",
    "image_paths = [x for x in pathlib.Path(TRAIN_IMAGE_DIR).rglob('*.jpg')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read image and resize it\n",
    "def read_image(image_path, size = (384, 384)):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, size)\n",
    "    return img\n",
    "def get_tf_records(record = 0, size = (384, 384)):\n",
    "    # Get only one group, this is a slow process so we need to make 50 different sessions\n",
    "    df_rec = df[df['group'] == record]\n",
    "    # Reset index \n",
    "    df_rec.reset_index(drop = True, inplace = True)\n",
    "    # Get a list of ids\n",
    "    ids_list = list(df_rec['id'].unique())\n",
    "    # Write tf records\n",
    "    with tf.io.TFRecordWriter('train_{}.tfrec'.format(record)) as writer:\n",
    "        for image_path in tqdm(image_paths):\n",
    "            image_id = image_path.name.split('.')[0]\n",
    "            if image_id in ids_list:\n",
    "                # Get target\n",
    "                target = df_rec[df_rec['id'] == image_id]['landmark_id_encode']\n",
    "                img = read_image(str(image_path), size)\n",
    "                img = cv2.imencode('.jpg', img, (cv2.IMWRITE_JPEG_QUALITY, 100))[1].tostring()\n",
    "                example = serialize_example(\n",
    "                    str.encode(image_id), img, target.values[0]\n",
    "                )\n",
    "                writer.write(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1580470 [00:00<?, ?it/s]/var/folders/g6/xjmqzxt515z147xzc4yys5j40000gn/T/ipykernel_52544/3647660849.py:22: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  img = cv2.imencode('.jpg', img, (cv2.IMWRITE_JPEG_QUALITY, 100))[1].tostring()\n",
      "2022-04-08 00:43:43.291446: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-08 00:43:43.291723: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "  0%|          | 182/1580470 [00:00<28:35, 921.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1580470/1580470 [19:04<00:00, 1381.46it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(TRAIN)\n",
    "get_tf_records(record = 0, size = (384, 384))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1580470 [00:00<?, ?it/s]/var/folders/g6/xjmqzxt515z147xzc4yys5j40000gn/T/ipykernel_52544/3647660849.py:22: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  img = cv2.imencode('.jpg', img, (cv2.IMWRITE_JPEG_QUALITY, 100))[1].tostring()\n",
      "100%|██████████| 1580470/1580470 [19:08<00:00, 1375.89it/s]\n",
      "100%|██████████| 1580470/1580470 [19:09<00:00, 1374.36it/s]\n",
      "100%|██████████| 1580470/1580470 [19:07<00:00, 1377.75it/s]\n",
      "100%|██████████| 1580470/1580470 [18:33<00:00, 1419.74it/s]\n",
      "100%|██████████| 1580470/1580470 [18:26<00:00, 1428.67it/s]\n",
      "100%|██████████| 1580470/1580470 [18:33<00:00, 1419.15it/s]\n",
      "100%|██████████| 1580470/1580470 [18:48<00:00, 1400.00it/s]\n",
      "100%|██████████| 1580470/1580470 [18:45<00:00, 1404.05it/s]\n",
      "100%|██████████| 1580470/1580470 [18:47<00:00, 1402.25it/s]\n",
      "100%|██████████| 1580470/1580470 [18:52<00:00, 1396.12it/s]\n",
      "100%|██████████| 1580470/1580470 [18:47<00:00, 1402.32it/s]\n",
      "100%|██████████| 1580470/1580470 [18:25<00:00, 1429.01it/s]\n",
      "100%|██████████| 1580470/1580470 [18:16<00:00, 1441.37it/s]\n",
      "100%|██████████| 1580470/1580470 [17:58<00:00, 1465.58it/s]\n",
      "100%|██████████| 1580470/1580470 [17:48<00:00, 1478.61it/s]\n",
      "100%|██████████| 1580470/1580470 [17:42<00:00, 1487.41it/s]\n",
      "100%|██████████| 1580470/1580470 [17:24<00:00, 1513.85it/s]\n",
      "100%|██████████| 1580470/1580470 [17:38<00:00, 1492.84it/s]\n",
      "100%|██████████| 1580470/1580470 [18:00<00:00, 1462.61it/s]\n",
      "100%|██████████| 1580470/1580470 [18:35<00:00, 1416.32it/s]\n",
      "100%|██████████| 1580470/1580470 [18:32<00:00, 1421.25it/s]\n",
      "100%|██████████| 1580470/1580470 [18:14<00:00, 1443.42it/s]\n",
      "100%|██████████| 1580470/1580470 [18:36<00:00, 1415.23it/s]\n",
      "100%|██████████| 1580470/1580470 [18:10<00:00, 1449.12it/s]\n",
      "100%|██████████| 1580470/1580470 [18:32<00:00, 1420.43it/s]\n",
      "100%|██████████| 1580470/1580470 [18:36<00:00, 1415.03it/s]\n",
      "100%|██████████| 1580470/1580470 [19:58<00:00, 1318.31it/s]\n",
      "100%|██████████| 1580470/1580470 [23:43<00:00, 1110.11it/s]\n",
      "100%|██████████| 1580470/1580470 [24:50<00:00, 1060.61it/s]\n",
      "100%|██████████| 1580470/1580470 [19:13<00:00, 1369.66it/s]\n",
      " 38%|███▊      | 603177/1580470 [06:40<10:49, 1504.95it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/satyamvatts/dev/gitrepos/cpsc_kaggle/CPSC_EXAM_EFNET.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/satyamvatts/dev/gitrepos/cpsc_kaggle/CPSC_EXAM_EFNET.ipynb#ch0000015?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m,\u001b[39m50\u001b[39m):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/satyamvatts/dev/gitrepos/cpsc_kaggle/CPSC_EXAM_EFNET.ipynb#ch0000015?line=1'>2</a>\u001b[0m     get_tf_records(record \u001b[39m=\u001b[39;49m i, size \u001b[39m=\u001b[39;49m (\u001b[39m384\u001b[39;49m, \u001b[39m384\u001b[39;49m))\n",
      "\u001b[1;32m/Users/satyamvatts/dev/gitrepos/cpsc_kaggle/CPSC_EXAM_EFNET.ipynb Cell 8'\u001b[0m in \u001b[0;36mget_tf_records\u001b[0;34m(record, size)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/satyamvatts/dev/gitrepos/cpsc_kaggle/CPSC_EXAM_EFNET.ipynb#ch0000009?line=17'>18</a>\u001b[0m \u001b[39mif\u001b[39;00m image_id \u001b[39min\u001b[39;00m ids_list:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/satyamvatts/dev/gitrepos/cpsc_kaggle/CPSC_EXAM_EFNET.ipynb#ch0000009?line=18'>19</a>\u001b[0m     \u001b[39m# Get target\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/satyamvatts/dev/gitrepos/cpsc_kaggle/CPSC_EXAM_EFNET.ipynb#ch0000009?line=19'>20</a>\u001b[0m     target \u001b[39m=\u001b[39m df_rec[df_rec[\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m image_id][\u001b[39m'\u001b[39m\u001b[39mlandmark_id_encode\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/satyamvatts/dev/gitrepos/cpsc_kaggle/CPSC_EXAM_EFNET.ipynb#ch0000009?line=20'>21</a>\u001b[0m     img \u001b[39m=\u001b[39m read_image(\u001b[39mstr\u001b[39;49m(image_path), size)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/satyamvatts/dev/gitrepos/cpsc_kaggle/CPSC_EXAM_EFNET.ipynb#ch0000009?line=21'>22</a>\u001b[0m     img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimencode(\u001b[39m'\u001b[39m\u001b[39m.jpg\u001b[39m\u001b[39m'\u001b[39m, img, (cv2\u001b[39m.\u001b[39mIMWRITE_JPEG_QUALITY, \u001b[39m100\u001b[39m))[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mtostring()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/satyamvatts/dev/gitrepos/cpsc_kaggle/CPSC_EXAM_EFNET.ipynb#ch0000009?line=22'>23</a>\u001b[0m     example \u001b[39m=\u001b[39m serialize_example(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/satyamvatts/dev/gitrepos/cpsc_kaggle/CPSC_EXAM_EFNET.ipynb#ch0000009?line=23'>24</a>\u001b[0m         \u001b[39mstr\u001b[39m\u001b[39m.\u001b[39mencode(image_id), img, target\u001b[39m.\u001b[39mvalues[\u001b[39m0\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/satyamvatts/dev/gitrepos/cpsc_kaggle/CPSC_EXAM_EFNET.ipynb#ch0000009?line=24'>25</a>\u001b[0m     )\n",
      "\u001b[1;32m/Users/satyamvatts/dev/gitrepos/cpsc_kaggle/CPSC_EXAM_EFNET.ipynb Cell 8'\u001b[0m in \u001b[0;36mread_image\u001b[0;34m(image_path, size)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/satyamvatts/dev/gitrepos/cpsc_kaggle/CPSC_EXAM_EFNET.ipynb#ch0000009?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_image\u001b[39m(image_path, size \u001b[39m=\u001b[39m (\u001b[39m384\u001b[39m, \u001b[39m384\u001b[39m)):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/satyamvatts/dev/gitrepos/cpsc_kaggle/CPSC_EXAM_EFNET.ipynb#ch0000009?line=2'>3</a>\u001b[0m     img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mimread(image_path)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/satyamvatts/dev/gitrepos/cpsc_kaggle/CPSC_EXAM_EFNET.ipynb#ch0000009?line=3'>4</a>\u001b[0m     img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(img, cv2\u001b[39m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/satyamvatts/dev/gitrepos/cpsc_kaggle/CPSC_EXAM_EFNET.ipynb#ch0000009?line=4'>5</a>\u001b[0m     img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mresize(img, size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(1,50):\n",
    "    get_tf_records(record = i, size = (384, 384))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import efficientnet.tfkeras as efn\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow_addons as tfa\n",
    "from tqdm.notebook import tqdm as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truths = pd.read_csv(TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "AUTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For tf.dataset\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# # Data access\n",
    "DICT_PATH = 'landmark-recognition-2020/train_encoded.csv'\n",
    "\n",
    "# Configuration\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = [384, 384]\n",
    "# Seed\n",
    "SEED = 100\n",
    "# Learning rate\n",
    "LR = 0.0001\n",
    "# Number of classes\n",
    "NUMBER_OF_CLASSES = 66672\n",
    "strategy = tf.distribute.get_strategy()\n",
    "\n",
    "# # Training filenames directory\n",
    "FILENAMES = tf.io.gfile.glob('./train*.tfrec')\n",
    "# # Read csv file\n",
    "df = pd.read_csv(DICT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAMES = FILENAMES[:5]\n",
    "NUMBER_OF_CLASSES = 37874\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./train_5.tfrec',\n",
       " './train_10.tfrec',\n",
       " './train_12.tfrec',\n",
       " './train_7.tfrec',\n",
       " './train_3.tfrec']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILENAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique training classes is 37349 of 37874 total classes\n",
      "The number of unique validation classes is 24639 of 37874 total classes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Using 20% of the data to validate\n",
    "TRAINING_FILENAMES, VALIDATION_FILENAMES = train_test_split(FILENAMES, test_size = 0.20, random_state = SEED)\n",
    "training_groups = [int(re.compile(r\"_([0-9]*)\\.\").search(filename).group(1)) for filename in TRAINING_FILENAMES]\n",
    "validation_groups = [int(re.compile(r\"_([0-9]*)\\.\").search(filename).group(1)) for filename in VALIDATION_FILENAMES]\n",
    "n_trn_classes = df[df['group'].isin(training_groups)]['landmark_id_encode'].nunique()\n",
    "n_val_classes = df[df['group'].isin(validation_groups)]['landmark_id_encode'].nunique()\n",
    "print(f'The number of unique training classes is {n_trn_classes} of {NUMBER_OF_CLASSES} total classes')\n",
    "print(f'The number of unique validation classes is {n_val_classes} of {NUMBER_OF_CLASSES} total classes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Seed everything\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "# Function to decode our images (normalize and reshape)\n",
    "def decode_image(image_data):\n",
    "    image = tf.image.decode_jpeg(image_data, channels = 3)\n",
    "    # Convert image to floats in [0, 1] range\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    # Explicit size needed for TPU\n",
    "    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n",
    "    return image\n",
    "\n",
    "# This function parse our images and also get the target variable\n",
    "def read_tfrecord(example):\n",
    "    TFREC_FORMAT = {\n",
    "        # tf.string means bytestring\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string), \n",
    "        # shape [] means single element\n",
    "        \"target\": tf.io.FixedLenFeature([], tf.int64)\n",
    "        }\n",
    "    example = tf.io.parse_single_example(example, TFREC_FORMAT)\n",
    "    image = decode_image(example['image'])\n",
    "    target = tf.cast(example['target'], tf.int32)\n",
    "    return image, target\n",
    "\n",
    "# This function load our tf records and parse our data with the previous function\n",
    "def load_dataset(filenames, ordered = False):\n",
    "    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n",
    "    # Diregarding data order. Order does not matter since we will be shuffling the data anyway\n",
    "    \n",
    "    ignore_order = tf.data.Options()\n",
    "    if not ordered:\n",
    "        # Disable order, increase speed\n",
    "        ignore_order.experimental_deterministic = False \n",
    "        \n",
    "    # Automatically interleaves reads from multiple files\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads = AUTO)\n",
    "    # Use data as soon as it streams in, rather than in its original order\n",
    "    dataset = dataset.with_options(ignore_order)\n",
    "    # Returns a dataset of (image, label) pairs\n",
    "    dataset = dataset.map(read_tfrecord, num_parallel_calls = AUTO) \n",
    "    return dataset\n",
    "\n",
    "# This function output the data so that we can use arcface\n",
    "def arcface_format(image, target):\n",
    "    return {'inp1': image, 'inp2': target}, target\n",
    "\n",
    "# Training data pipeline\n",
    "def get_training_dataset(filenames, ordered = False):\n",
    "    dataset = load_dataset(filenames, ordered = ordered)\n",
    "    dataset = dataset.map(arcface_format, num_parallel_calls = AUTO)\n",
    "    # The training dataset must repeat for several epochs\n",
    "    dataset = dataset.repeat() \n",
    "    dataset = dataset.shuffle(2048)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    # Prefetch next batch while training (autotune prefetch buffer size)\n",
    "    dataset = dataset.prefetch(AUTO)\n",
    "    return dataset\n",
    "\n",
    "# Validation data pipeline\n",
    "def get_validation_dataset(filenames, ordered = True, prediction = False):\n",
    "    dataset = load_dataset(filenames, ordered = ordered)\n",
    "    dataset = dataset.map(arcface_format, num_parallel_calls = AUTO)\n",
    "    # If we are in prediction mode, use bigger batch size for faster prediction\n",
    "    if prediction:\n",
    "        dataset = dataset.batch(BATCH_SIZE * 4)\n",
    "    else:\n",
    "        dataset = dataset.batch(BATCH_SIZE)\n",
    "    # Prefetch next batch while training (autotune prefetch buffer size)\n",
    "    dataset = dataset.prefetch(AUTO) \n",
    "    return dataset\n",
    "\n",
    "# Count the number of observations with the tabular csv\n",
    "def count_data_items(filenames):\n",
    "    records = [int(re.compile(r\"_([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
    "    df = pd.read_csv(DICT_PATH)\n",
    "    n = df[df['group'].isin(records)].shape[0]\n",
    "    return n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 126440 images\n",
      "Validating with 31610 images\n"
     ]
    }
   ],
   "source": [
    "\n",
    "NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\n",
    "NUM_VALIDATION_IMAGES  = count_data_items(VALIDATION_FILENAMES)\n",
    "print(f'Training with {NUM_TRAINING_IMAGES} images')\n",
    "print(f'Validating with {NUM_VALIDATION_IMAGES} images')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function for a custom learning rate scheduler with warmup and decay\n",
    "def get_lr_callback():\n",
    "    lr_start   = 0.000001\n",
    "    lr_max     = 0.0000005 * BATCH_SIZE\n",
    "    lr_min     = 0.000001\n",
    "    lr_ramp_ep = 5\n",
    "    lr_sus_ep  = 0\n",
    "    lr_decay   = 0.8\n",
    "   \n",
    "    def lrfn(epoch):\n",
    "        if epoch < lr_ramp_ep:\n",
    "            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start   \n",
    "        elif epoch < lr_ramp_ep + lr_sus_ep:\n",
    "            lr = lr_max    \n",
    "        else:\n",
    "            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min    \n",
    "        return lr\n",
    "\n",
    "    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose = False)\n",
    "    return lr_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate global average precision score\n",
    "def gap_vector(pred, conf, true, return_x = False):\n",
    "    '''\n",
    "    Compute Global Average Precision (aka micro AP), the metric for the\n",
    "    Google Landmark Recognition competition. \n",
    "    This function takes predictions, labels and confidence scores as vectors.\n",
    "    In both predictions and ground-truth, use None/np.nan for \"no label\".\n",
    "\n",
    "    Args:\n",
    "        pred: vector of integer-coded predictions\n",
    "        conf: vector of probability or confidence scores for pred\n",
    "        true: vector of integer-coded labels for ground truth\n",
    "        return_x: also return the data frame used in the calculation\n",
    "\n",
    "    Returns:\n",
    "        GAP score\n",
    "    '''\n",
    "    x = pd.DataFrame({'pred': pred, 'conf': conf, 'true': true})\n",
    "    x.sort_values('conf', ascending = False, inplace = True, na_position = 'last')\n",
    "    x['correct'] = (x.true == x.pred).astype(int)\n",
    "    x['prec_k'] = x.correct.cumsum() / (np.arange(len(x)) + 1)\n",
    "    x['term'] = x.prec_k * x.correct\n",
    "    gap = x.term.sum() / x.true.count()\n",
    "    if return_x:\n",
    "        return gap, x\n",
    "    else:\n",
    "        return gap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArcMarginProduct(tf.keras.layers.Layer):\n",
    "    '''\n",
    "    Implements large margin arc distance.\n",
    "\n",
    "    Reference:\n",
    "        https://arxiv.org/pdf/1801.07698.pdf\n",
    "        https://github.com/lyakaap/Landmark2019-1st-and-3rd-Place-Solution/\n",
    "            blob/master/src/modeling/metric_learning.py\n",
    "    '''\n",
    "    def __init__(self, n_classes, s=30, m=0.50, easy_margin=False,\n",
    "                 ls_eps=0.0, **kwargs):\n",
    "\n",
    "        super(ArcMarginProduct, self).__init__(**kwargs)\n",
    "\n",
    "        self.n_classes = n_classes\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.ls_eps = ls_eps\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = tf.math.cos(m)\n",
    "        self.sin_m = tf.math.sin(m)\n",
    "        self.th = tf.math.cos(math.pi - m)\n",
    "        self.mm = tf.math.sin(math.pi - m) * m\n",
    "\n",
    "    def get_config(self):\n",
    "\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'n_classes': self.n_classes,\n",
    "            's': self.s,\n",
    "            'm': self.m,\n",
    "            'ls_eps': self.ls_eps,\n",
    "            'easy_margin': self.easy_margin,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(ArcMarginProduct, self).build(input_shape[0])\n",
    "\n",
    "        self.W = self.add_weight(\n",
    "            name='W',\n",
    "            shape=(int(input_shape[0][-1]), self.n_classes),\n",
    "            initializer='glorot_uniform',\n",
    "            dtype='float32',\n",
    "            trainable=True,\n",
    "            regularizer=None)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        X, y = inputs\n",
    "        y = tf.cast(y, dtype=tf.int32)\n",
    "        cosine = tf.matmul(\n",
    "            tf.math.l2_normalize(X, axis=1),\n",
    "            tf.math.l2_normalize(self.W, axis=0)\n",
    "        )\n",
    "        sine = tf.math.sqrt(1.0 - tf.math.pow(cosine, 2))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        if self.easy_margin:\n",
    "            phi = tf.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = tf.where(cosine > self.th, phi, cosine - self.mm)\n",
    "        one_hot = tf.cast(\n",
    "            tf.one_hot(y, depth=self.n_classes),\n",
    "            dtype=cosine.dtype\n",
    "        )\n",
    "        if self.ls_eps > 0:\n",
    "            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.n_classes\n",
    "\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        output *= self.s\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build our model using fine tunning (efficientnet)\n",
    "def get_model():\n",
    "\n",
    "    with strategy.scope():\n",
    "\n",
    "        margin = ArcMarginProduct(\n",
    "            n_classes = NUMBER_OF_CLASSES, \n",
    "            s = 64, \n",
    "            m = 0.05, \n",
    "            name='head/arc_margin', \n",
    "            dtype='float32'\n",
    "            )\n",
    "\n",
    "        inp = tf.keras.layers.Input(shape = (*IMAGE_SIZE, 3), name = 'inp1')\n",
    "        label = tf.keras.layers.Input(shape = (), name = 'inp2')\n",
    "        x0 = efn.EfficientNetB0(weights = 'imagenet', include_top = False)(inp)\n",
    "        x = tf.keras.layers.GlobalAveragePooling2D()(x0)\n",
    "        x = tf.keras.layers.Dropout(0.3)(x)\n",
    "        x = tf.keras.layers.Dense(512)(x)\n",
    "        x = margin([x, label])\n",
    "        \n",
    "        output = tf.keras.layers.Softmax(dtype='float32')(x)\n",
    "\n",
    "        model = tf.keras.models.Model(inputs = [inp, label], outputs = [output])\n",
    "\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate = LR)\n",
    "\n",
    "        model.compile(\n",
    "            optimizer = opt,\n",
    "            loss = [tf.keras.losses.SparseCategoricalCrossentropy()],\n",
    "            metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    "            ) \n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed everything\n",
    "seed_everything(SEED)\n",
    "\n",
    "# Build training and validation generators\n",
    "train_dataset = get_training_dataset(TRAINING_FILENAMES, ordered = False)\n",
    "val_dataset = get_validation_dataset(VALIDATION_FILENAMES, ordered = True, prediction = False)\n",
    "STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "# Using a checkpoint to save best model (want the entire model, not only the weights)\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'baseline_model_effb0_arcface.h5', \n",
    "                                                 monitor = 'val_loss', \n",
    "                                                 save_best_only = True, \n",
    "                                                 save_weights_only = False)\n",
    "# Using learning rate scheduler\n",
    "cb_lr_schedule = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_loss', \n",
    "                                                       mode = 'min', \n",
    "                                                       factor = 0.5, \n",
    "                                                       patience = 1, \n",
    "                                                       verbose = 1, \n",
    "                                                       min_delta = 0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-08 12:00:05.368435: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  60/3951 [..............................] - ETA: 3:27:09 - loss: 8.1922 - sparse_categorical_accuracy: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/satyamvatts/dev/gitrepos/cpsc_kaggle/CPSC_EXAM_EFNET.ipynb Cell 28'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/satyamvatts/dev/gitrepos/cpsc_kaggle/CPSC_EXAM_EFNET.ipynb#ch0000038?line=0'>1</a>\u001b[0m \u001b[39m# Train and evaluate our model\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/satyamvatts/dev/gitrepos/cpsc_kaggle/CPSC_EXAM_EFNET.ipynb#ch0000038?line=1'>2</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_dataset,  \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/satyamvatts/dev/gitrepos/cpsc_kaggle/CPSC_EXAM_EFNET.ipynb#ch0000038?line=2'>3</a>\u001b[0m                     steps_per_epoch \u001b[39m=\u001b[39;49m STEPS_PER_EPOCH,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/satyamvatts/dev/gitrepos/cpsc_kaggle/CPSC_EXAM_EFNET.ipynb#ch0000038?line=3'>4</a>\u001b[0m                     epochs \u001b[39m=\u001b[39;49m EPOCHS,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/satyamvatts/dev/gitrepos/cpsc_kaggle/CPSC_EXAM_EFNET.ipynb#ch0000038?line=4'>5</a>\u001b[0m                     \u001b[39m# callbacks = [get_lr_callback(), checkpoint],\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/satyamvatts/dev/gitrepos/cpsc_kaggle/CPSC_EXAM_EFNET.ipynb#ch0000038?line=5'>6</a>\u001b[0m                     validation_data \u001b[39m=\u001b[39;49m val_dataset,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/satyamvatts/dev/gitrepos/cpsc_kaggle/CPSC_EXAM_EFNET.ipynb#ch0000038?line=6'>7</a>\u001b[0m                     verbose \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/satyamvatts/dev/gitrepos/cpsc_kaggle/CPSC_EXAM_EFNET.ipynb#ch0000038?line=7'>8</a>\u001b[0m                     )\n",
      "File \u001b[0;32m~/miniforge3/envs/mlp/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/keras/utils/traceback_utils.py?line=61'>62</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/keras/utils/traceback_utils.py?line=62'>63</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/keras/utils/traceback_utils.py?line=63'>64</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/mlp/lib/python3.8/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/keras/engine/training.py?line=1376'>1377</a>\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/keras/engine/training.py?line=1377'>1378</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/keras/engine/training.py?line=1378'>1379</a>\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/keras/engine/training.py?line=1379'>1380</a>\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/keras/engine/training.py?line=1380'>1381</a>\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/keras/engine/training.py?line=1381'>1382</a>\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/keras/engine/training.py?line=1382'>1383</a>\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/keras/engine/training.py?line=1383'>1384</a>\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/keras/engine/training.py?line=1384'>1385</a>\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/keras/engine/training.py?line=1385'>1386</a>\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py?line=147'>148</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py?line=148'>149</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py?line=149'>150</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py?line=150'>151</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py?line=151'>152</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=911'>912</a>\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=913'>914</a>\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=914'>915</a>\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=916'>917</a>\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=917'>918</a>\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=943'>944</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=944'>945</a>\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=945'>946</a>\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=946'>947</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=947'>948</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=948'>949</a>\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=949'>950</a>\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py?line=950'>951</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=2952'>2953</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=2953'>2954</a>\u001b[0m   (graph_function,\n\u001b[1;32m   <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=2954'>2955</a>\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=2955'>2956</a>\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=2956'>2957</a>\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1848'>1849</a>\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1849'>1850</a>\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1850'>1851</a>\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1851'>1852</a>\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1852'>1853</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1853'>1854</a>\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1854'>1855</a>\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1855'>1856</a>\u001b[0m     args,\n\u001b[1;32m   <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1856'>1857</a>\u001b[0m     possible_gradient_type,\n\u001b[1;32m   <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1857'>1858</a>\u001b[0m     executing_eagerly)\n\u001b[1;32m   <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=1858'>1859</a>\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=496'>497</a>\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=497'>498</a>\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=498'>499</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=499'>500</a>\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=500'>501</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=501'>502</a>\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=502'>503</a>\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=503'>504</a>\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=504'>505</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=505'>506</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=506'>507</a>\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=507'>508</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=510'>511</a>\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/function.py?line=511'>512</a>\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/execute.py?line=51'>52</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/execute.py?line=52'>53</a>\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/execute.py?line=53'>54</a>\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/execute.py?line=54'>55</a>\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/execute.py?line=55'>56</a>\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     <a href='file:///Users/satyamvatts/miniforge3/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/execute.py?line=56'>57</a>\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Train and evaluate our model\n",
    "history = model.fit(train_dataset,  \n",
    "                    steps_per_epoch = STEPS_PER_EPOCH,\n",
    "                    epochs = EPOCHS,\n",
    "                    # callbacks = [get_lr_callback(), checkpoint],\n",
    "                    validation_data = val_dataset,\n",
    "                    verbose = 1\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Restart tpu\n",
    "# tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "# # Load best model\n",
    "# model = tf.keras.models.load_model('/content/drive/My Drive/Models/baseline_model_effb0_arcface.h5')\n",
    "\n",
    "# # Reset val dataset, now in prediction mode\n",
    "# val_dataset = get_validation_dataset(VALIDATION_FILENAMES, ordered = True, prediction = True)\n",
    "# # Get ground truth target for the fold\n",
    "# val_target = val_dataset.map(lambda image, target: target).unbatch()\n",
    "# val_targets = list(next(iter(val_target.batch(NUM_VALIDATION_IMAGES))).numpy())\n",
    "\n",
    "#  # Predictions\n",
    "# val_image = val_dataset.map(lambda image, target: image['inp1'])\n",
    "# # Transform validation dataset as a numpy iterator\n",
    "# val_image = val_image.as_numpy_iterator()\n",
    "# # Initiate empty list to store predictions and confidences\n",
    "# target_predictions = []\n",
    "# target_confidences = []\n",
    "# # Iterate over validation images and predict in batches of 1024 images\n",
    "# batches = math.ceil(NUM_VALIDATION_IMAGES / (BATCH_SIZE * 4))\n",
    "# for image in tqdm(val_image, total = batches):\n",
    "#     prediction = model.predict(image)\n",
    "#     target_prediction = np.argmax(prediction, axis = -1)\n",
    "#     target_confidence = np.max(prediction, axis = -1)\n",
    "#     target_predictions.extend(list(target_prediction))\n",
    "#     target_confidences.extend(list(target_confidence))\n",
    "\n",
    "# # Calculate global average precision for the fold\n",
    "# gap = gap_vector(target_predictions, target_confidences, val_targets)\n",
    "# accuracy_score = metrics.accuracy_score(val_targets, target_predictions)\n",
    "# print(f'Our global average precision score is {gap}')\n",
    "# print(f'Our accuracy score is {accuracy_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>landmark_id</th>\n",
       "      <th>landmark_id_encode</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1042527</th>\n",
       "      <td>1c3654818c768b2c</td>\n",
       "      <td>134466</td>\n",
       "      <td>54000</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613554</th>\n",
       "      <td>fed703fc407ea6cb</td>\n",
       "      <td>78875</td>\n",
       "      <td>31731</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158442</th>\n",
       "      <td>a781aff8a80fe610</td>\n",
       "      <td>20409</td>\n",
       "      <td>8211</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795783</th>\n",
       "      <td>7317abdb5266aaf6</td>\n",
       "      <td>102839</td>\n",
       "      <td>41351</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042519</th>\n",
       "      <td>143ad48bc9990f56</td>\n",
       "      <td>134466</td>\n",
       "      <td>54000</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id  landmark_id  landmark_id_encode  group\n",
       "1042527  1c3654818c768b2c       134466               54000   32.0\n",
       "613554   fed703fc407ea6cb        78875               31731   23.0\n",
       "158442   a781aff8a80fe610        20409                8211   38.0\n",
       "795783   7317abdb5266aaf6       102839               41351   31.0\n",
       "1042519  143ad48bc9990f56       134466               54000   25.0"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('landmark-recognition-2020/train_encoded.csv')\n",
    "sample_df = train_df.sample(frac=0.7, random_state=1234)\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df_classes = sample_df['landmark_id_encode'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55807    4379\n",
       "50843    1578\n",
       "8211     1229\n",
       "33462    1199\n",
       "45494     802\n",
       "         ... \n",
       "54074     100\n",
       "49146     100\n",
       "72633     100\n",
       "61231     100\n",
       "40704     100\n",
       "Name: landmark_id_encode, Length: 996, dtype: int64"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df_classes_with_at_least_100 = sample_df_classes[sample_df_classes >= 100]\n",
    "sample_df_classes_with_at_least_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175809"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df_classes_with_at_least_100.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clas in sample_df_classes_with_at_least_100.index:\n",
    "    if not os.path.exists(f'Data/train/{clas}'):\n",
    "        os.makedirs(f'Data/train/{clas}')\n",
    "    if not os.path.exists(f'Data/test/{clas}'):\n",
    "        os.makedirs(f'Data/test/{clas}')\n",
    "    if not os.path.exists(f'Data/val/{clas}'):\n",
    "        os.makedirs(f'Data/val/{clas}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for clas in sample_df_classes_with_at_least_100.index:\n",
    "    train_images_df = sample_df[sample_df['landmark_id_encode'] == clas].sample(frac=0.8)\n",
    "    test_df = sample_df[(sample_df['landmark_id_encode'] == clas) & ~sample_df['id'].isin(train_images_df['id'])]\n",
    "    train_df = train_images_df.sample(frac=0.7)\n",
    "    val_df = train_images_df[~train_images_df['id'].isin(train_df['id'])]\n",
    "    \n",
    "    for img in train_df['id'].values:\n",
    "        f1 = img[0]\n",
    "        f2 = img[1]\n",
    "        f3 = img[2]\n",
    "        img_path = f\"landmark-recognition-2020/train/{f1}/{f2}/{f3}/{img}.jpg\"\n",
    "        if not os.path.exists(f'Data/train/{clas}/{img}.jpg'):\n",
    "            shutil.copyfile(img_path, f'Data/train/{clas}/{img}.jpg')\n",
    "    for img in test_df['id'].values:\n",
    "        f1 = img[0]\n",
    "        f2 = img[1]\n",
    "        f3 = img[2]\n",
    "        img_path = f\"landmark-recognition-2020/train/{f1}/{f2}/{f3}/{img}.jpg\"\n",
    "        if not os.path.exists(f'Data/test/{clas}/{img}.jpg'):\n",
    "            shutil.copyfile(img_path, f'Data/test/{clas}/{img}.jpg')\n",
    "    for img in val_df['id'].values:\n",
    "        f1 = img[0]\n",
    "        f2 = img[1]\n",
    "        f3 = img[2]\n",
    "        img_path = f\"landmark-recognition-2020/train/{f1}/{f2}/{f3}/{img}.jpg\"\n",
    "        if not os.path.exists(f'Data/val/{clas}/{img}.jpg'):\n",
    "            shutil.copyfile(img_path, f'Data/val/{clas}/{img}.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "65acd4c9d4fd6733d7ab637faeb0b04fd086d66836c070d09357b7a84dadd4e3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('mlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
